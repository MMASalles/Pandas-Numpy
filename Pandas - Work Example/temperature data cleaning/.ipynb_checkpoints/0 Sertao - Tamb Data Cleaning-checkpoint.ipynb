{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sertao - Tamb Data Filtering & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps in this file:**\n",
    "\n",
    "- **Step 1 -** Repeating values are removed\n",
    "\n",
    "- **Step 2 -** Identical values across pyranometers are removed\n",
    "\n",
    "- **Step 3 -** Outliers (data point two standard deviations or 3% away from the mean) are removed\n",
    "\n",
    "- **Step 4 -** Less than 3hrs gaps: Fill in by lineary interpolation (check start point, end point, and fill linearly) \n",
    "\n",
    "- **Step 5 -** Other timesteps: Null data will be estimated using the previous and next day (same timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "-  Setting first column as dataframe index\n",
    "-  Automatically interpreting date-like values as dates through 'parse_dates=True'\n",
    "-  Interpreting dates with format dd/mm/yyyy through 'dayfirst=True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"2 SMR - Tamb Data 10T - Timestep Cleaning.csv\",index_col=0, parse_dates=True, dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 48667 entries, 2019-04-01 00:00:00 to 2020-03-03 23:00:00\n",
      "Data columns (total 18 columns):\n",
      "MET01    47535 non-null float64\n",
      "MET02    47535 non-null float64\n",
      "MET03    47535 non-null float64\n",
      "MET04    47535 non-null float64\n",
      "MET05    47535 non-null float64\n",
      "MET06    47535 non-null float64\n",
      "MET07    47535 non-null float64\n",
      "MET08    47535 non-null float64\n",
      "MET09    47535 non-null float64\n",
      "MET10    47535 non-null float64\n",
      "MET11    47535 non-null float64\n",
      "MET12    47535 non-null float64\n",
      "MET13    47535 non-null float64\n",
      "MET14    47535 non-null float64\n",
      "MET15    47535 non-null float64\n",
      "MET16    47535 non-null float64\n",
      "MET17    47535 non-null float64\n",
      "MET18    47535 non-null float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 7.1 MB\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MET01</th>\n",
       "      <th>MET02</th>\n",
       "      <th>MET03</th>\n",
       "      <th>MET04</th>\n",
       "      <th>MET05</th>\n",
       "      <th>MET06</th>\n",
       "      <th>MET07</th>\n",
       "      <th>MET08</th>\n",
       "      <th>MET09</th>\n",
       "      <th>MET10</th>\n",
       "      <th>MET11</th>\n",
       "      <th>MET12</th>\n",
       "      <th>MET13</th>\n",
       "      <th>MET14</th>\n",
       "      <th>MET15</th>\n",
       "      <th>MET16</th>\n",
       "      <th>MET17</th>\n",
       "      <th>MET18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 00:00:00</th>\n",
       "      <td>10.07</td>\n",
       "      <td>10.19</td>\n",
       "      <td>10.15</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.98</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.36</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.89</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.11</td>\n",
       "      <td>10.69</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9.81</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.24</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 00:10:00</th>\n",
       "      <td>10.39</td>\n",
       "      <td>10.11</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.16</td>\n",
       "      <td>9.69</td>\n",
       "      <td>10.35</td>\n",
       "      <td>10.21</td>\n",
       "      <td>9.74</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.92</td>\n",
       "      <td>10.32</td>\n",
       "      <td>10.17</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.68</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.46</td>\n",
       "      <td>10.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 00:20:00</th>\n",
       "      <td>9.78</td>\n",
       "      <td>9.71</td>\n",
       "      <td>10.34</td>\n",
       "      <td>9.93</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.24</td>\n",
       "      <td>10.41</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.86</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.37</td>\n",
       "      <td>10.05</td>\n",
       "      <td>9.04</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.89</td>\n",
       "      <td>9.40</td>\n",
       "      <td>10.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 00:30:00</th>\n",
       "      <td>9.36</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.51</td>\n",
       "      <td>9.17</td>\n",
       "      <td>9.25</td>\n",
       "      <td>10.42</td>\n",
       "      <td>10.78</td>\n",
       "      <td>9.68</td>\n",
       "      <td>10.17</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.31</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>9.21</td>\n",
       "      <td>9.91</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 00:40:00</th>\n",
       "      <td>10.17</td>\n",
       "      <td>10.18</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.21</td>\n",
       "      <td>8.83</td>\n",
       "      <td>10.05</td>\n",
       "      <td>10.24</td>\n",
       "      <td>9.43</td>\n",
       "      <td>9.82</td>\n",
       "      <td>8.91</td>\n",
       "      <td>9.19</td>\n",
       "      <td>10.34</td>\n",
       "      <td>9.95</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.09</td>\n",
       "      <td>8.56</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MET01  MET02  MET03  MET04  MET05  MET06  MET07  MET08  \\\n",
       "2019-04-01 00:00:00  10.07  10.19  10.15  10.13   9.98  10.61  10.36   9.70   \n",
       "2019-04-01 00:10:00  10.39  10.11  10.09  10.16   9.69  10.35  10.21   9.74   \n",
       "2019-04-01 00:20:00   9.78   9.71  10.34   9.93   9.91  10.24  10.41  10.30   \n",
       "2019-04-01 00:30:00   9.36   9.70   9.51   9.17   9.25  10.42  10.78   9.68   \n",
       "2019-04-01 00:40:00  10.17  10.18   9.12   9.21   8.83  10.05  10.24   9.43   \n",
       "\n",
       "                     MET09  MET10  MET11  MET12  MET13  MET14  MET15  MET16  \\\n",
       "2019-04-01 00:00:00   9.89  10.53  10.11  10.69  10.27   9.81   9.73  10.50   \n",
       "2019-04-01 00:10:00   9.67  10.00   9.92  10.32  10.17   9.53   9.68  10.30   \n",
       "2019-04-01 00:20:00  10.80   9.86   9.67  10.37  10.05   9.04   9.95   9.89   \n",
       "2019-04-01 00:30:00  10.17   9.53   9.31  10.66  10.09   9.21   9.91   9.36   \n",
       "2019-04-01 00:40:00   9.82   8.91   9.19  10.34   9.95   9.84  10.09   8.56   \n",
       "\n",
       "                     MET17  MET18  \n",
       "2019-04-01 00:00:00   9.24  10.50  \n",
       "2019-04-01 00:10:00   9.46  10.49  \n",
       "2019-04-01 00:20:00   9.40  10.19  \n",
       "2019-04-01 00:30:00   9.73  10.00  \n",
       "2019-04-01 00:40:00   9.48   9.77  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 0 - CREATE SUMMARY DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe is used to record the diffent cleaning (sub-)steps, to view impact of each step and ensure the order of the methodology is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average of initial file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df['Step 0'] = Data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 - REMOVE REPEATING VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panda's diff() function compares n values with their n-1 values\n",
    "\n",
    "Remove values if identical to value in previous timestep, as it indicates a communication error. \n",
    "\n",
    "Also removing values which varied by more than **3 degrees / 10min basis**. This value is arbitrary, and is to be re-assessed if timestep frequency is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_diff = Data.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate through MET_stations\n",
    "for MET_station in Data:\n",
    "\n",
    "    # Remove identical values using diff() function \n",
    "    Data[MET_station] = np.where(Data_diff[MET_station] == 0, np.nan, Data[MET_station])\n",
    "    \n",
    "    # Remove values if previous timestep is erroneous \n",
    "    #Data[MET_station] = np.where(Data_diff[MET_station].shift(1) == 0, np.nan, Data[MET_station])\n",
    "    \n",
    "    # Remove values if following timestep is erroneous\n",
    "    #Data[MET_station] = np.where(Data_diff[MET_station].shift(-1) == 0, np.nan, Data[MET_station])\n",
    "    \n",
    "    # Remove values if change in temperature is greater than +/-3 degrees Celsius / 10min \n",
    "    Data[MET_station] = np.where((Data_diff[MET_station] > 3) | (Data_diff[MET_station] < -3), np.nan, Data[MET_station])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df['Step 1'] = Data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 - REMOVING IDENTICAL VALUES ACROSS SENSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average (mean) and standard deviation (std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = Data.std(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Remove identical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard deviation of 0 mean that all of the temp sensors have the same value, which indicates a communication error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate through MET_stations\n",
    "for MET_station in Data:\n",
    "\n",
    "    # Remove values where standard deviation across timestep is zero\n",
    "    Data[MET_station] = np.where(std == 0, np.nan, Data[MET_station])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df['Step 2'] = Data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 - REMOVE OUTLIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare TempSensors value with lowest boundary and higher boundary (between 2 std away from mean, or 3%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyr_accuracy = 0.03\n",
    "average = Data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upper_std_boundary = average + (std * 2)\n",
    "Lower_std_boundary = average - (std * 2)\n",
    "Upper_accuracy_boundary = average * (1 + pyr_accuracy)\n",
    "Lower_accuracy_boundary = average * (1 - pyr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upper_boundary = np.maximum(Upper_std_boundary, Upper_accuracy_boundary)\n",
    "Lower_boundary = np.minimum(Lower_std_boundary, Lower_accuracy_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove value if outside boundaries otherwise keep values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate through MET_stations\n",
    "for MET_station in Data:\n",
    "\n",
    "    # Remove values outside of either boundaries\n",
    "    Data[MET_station] = np.where((Data[MET_station] > Upper_boundary) | (Data[MET_station] < Lower_boundary), \n",
    "                                 np.nan, Data[MET_station])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df['Step 3'] = Data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 - FILL IN DATA GAPS LESS THAN 3HRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mask of timesteps with valid data points & null datapoints if part of less than 3hr datagap (18 timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution from JohnE on https://stackoverflow.com/questions/30533021/interpolate-or-extrapolate-only-small-gaps-in-pandas-dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Data.copy()\n",
    "\n",
    "# Iterate through each MET Station\n",
    "for MET_Station in Data:\n",
    "    \n",
    "    # Create new DataFrame\n",
    "    df = pd.DataFrame(Data[MET_Station])\n",
    "    \n",
    "    #  This column counts the sequences of valid data points and sequences of nulls (resets when it encounters change)\n",
    "    df['new'] = ((df.notnull() != df.shift().notnull()).cumsum())\n",
    "    \n",
    "    # This column filled with 1s is required for the groupby function below  \n",
    "    df['ones'] = 1\n",
    "    \n",
    "    # Add to the mask if sequence is lower than 3hrs (18 timesteps), or contains valid datapoints.\n",
    "    mask[MET_Station] = (df.groupby('new')['ones'].transform('count') < 18) | Data[MET_Station].notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate any nulls in mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Data = Data.interpolate().bfill()[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df['Step 4'] = Data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 - FILL IN DATA GAPS MORE THAN 3HRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prev = Data.copy()\n",
    "Next = Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each MET Station\n",
    "for MET_Station in Data:\n",
    "\n",
    "    Prev[MET_Station] = Data.groupby([Data.index.hour, Data.index.minute])[MET_Station].shift(1)\n",
    "    Next[MET_Station] = Data.groupby([Data.index.hour, Data.index.minute])[MET_Station].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataFrame with (i) replacement values which will be amended, (ii) data shift by +1 day, (iii) data shifted by -1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Replacement = Data.copy()\n",
    "Replacement = Replacement.join(Prev, rsuffix='_Prev')\n",
    "Replacement = Replacement.join(Next, rsuffix='_Next')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amend replacement values to equate average between corresponding MET Station's previous and next values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each MET Station\n",
    "for MET_Station in Data:\n",
    "    Replacement[MET_Station] = Replacement[[MET_Station + '_Prev', MET_Station + '_Next']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only replacement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data[~mask] = Replacement[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df['Step 5'] = Data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6 - SAVE OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_df.to_csv(\"3 SMR - Tamb Data Cleaning - Summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_csv(\"3 SMR - Tamb Data 10T - Data Cleaning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final_df = pd.DataFrame(Summary_df['Step 5'])\n",
    "Final_df.rename(columns={'Step 5':'Tamb (°C)'}, inplace=True)\n",
    "Final_df.to_csv(\"3 SMR - Tamb Data 10T - Average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
